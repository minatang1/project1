{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FYS-STK4155 PROJECT 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Franke's Function\n",
    "Setting up Franke's function (as given in assignment text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FrankeFunction(x,y):\n",
    "    term1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "    term2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "    term3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "    term4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "    return term1 + term2 + term3 + term4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vandermonde Matrix (design matrix) of Degree $n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VandermondeMatrix(x, y, n):\n",
    "    X = np.c_[np.ones(len(x))]\n",
    "    for i in range(1, n+1):\n",
    "        # x-terms\n",
    "        X = np.c_[X, x**(i)]\n",
    "        # y-terms\n",
    "        X = np.c_[X, y**(i)]\n",
    "        # Cross terms\n",
    "        for j in range(i-1, 0, -1):\n",
    "            X = np.c_[X, (x**(j))*(y**(i-j))]\n",
    "            \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordinary Least-Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linreg_ols(X, z):\n",
    "    \n",
    "    # Solving for beta\n",
    "    beta = np.linalg.inv(np.transpose(X).dot(X)).dot(np.transpose(X)).dot(z)\n",
    "    \n",
    "    y_predict_ols = X @ beta\n",
    "    \n",
    "    return beta, y_predict_ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridgereg(X, z, lambda_ridge):\n",
    "\n",
    "    # Solving for beta\n",
    "    beta_ridge = np.linalg.inv(np.transpose(X).dot(X) + lambda_ridge*np.identity(X.shape[1])).dot(np.transpose(X)).dot(z)\n",
    "\n",
    "    y_predict_ridge = X @ beta_ridge\n",
    "    \n",
    "    return beta_ridge, y_predict_ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "def lassoreg(X, z, lambda_lasso):\n",
    "    \n",
    "    las = Lasso(alpha=lambda_lasso, fit_intercept = False)\n",
    "    las.fit(X, z)\n",
    "    \n",
    "    beta = las.coef_#[:,np.newaxis]\n",
    "    \n",
    "    y_predict_lasso = X @ beta\n",
    "    \n",
    "    R2_lasso = las.score(X, z)\n",
    "    \n",
    "    return beta, y_predict_lasso, R2_lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $R^{2}$ function (taken from lecture notes)\n",
    "\n",
    "The ideal fit gives $R^{2} = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def R2(y_data, y_model):\n",
    "    return 1 - np.sum((y_data - y_model) ** 2) / np.sum((y_data - np.mean(y_data)) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Squared Error (MSE) function\n",
    "\n",
    "The ideal fit gives $MSE = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MSE(y_data,y_model):\n",
    "    n = np.size(y_model)\n",
    "    return np.sum((y_data-y_model)**2)/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance\n",
    "\n",
    "(Find formula from book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Variance\n",
    "def var(y_data, y_model):\n",
    "    n = 20\n",
    "    return np.sum((y_model - np.mean(y_model))**2) / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confidence_interval(X, beta, z_level, std):\n",
    "    \n",
    "    XtXi = np.linalg.inv(np.transpose(X).dot(X))\n",
    "\n",
    "    num_beta = beta.shape[0]\n",
    "    \n",
    "    diagonals = np.zeros(num_beta)\n",
    "    \n",
    "    for j in range(num_beta):\n",
    "        diagonals[j] = np.sqrt(XtXi[j][j])\n",
    "        \n",
    "    cint_upper = np.zeros(num_beta)\n",
    "    cint_lower = np.zeros(num_beta)\n",
    "    \n",
    "    for i in range(num_beta):\n",
    "        \n",
    "        cint_upper[i] = beta[i] + z_level*std\n",
    "        cint_lower[i] = beta[i] - z_level*std\n",
    "        \n",
    "    return cint_upper, cint_lower, diagonals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **END OF FUNCTIONS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **START OF PROGRAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GENERATING DATA\n",
    "x = np.arange(0, 1, 0.05)\n",
    "y = np.arange(0, 1, 0.05)\n",
    "\n",
    "x, y = np.meshgrid(x, y)\n",
    "\n",
    "z = FrankeFunction(x, y)\n",
    "\n",
    "x = np.ravel(x)\n",
    "y = np.ravel(y)\n",
    "z = np.ravel(z)\n",
    "\n",
    "z = z #+ 0.1 * np.random.randn(z.shape[0]) # noise level = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# COMPARING WITH SCI-KIT LEARN\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression().fit(X, z)\n",
    "z_predict_scikit = X @ reg.coef_\n",
    "\n",
    "R2_scikit.append(reg.score(X, z))\n",
    "\n",
    "MSE_scikit.append(MSE(z, z_predict_scikit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "R2_scores = list()\n",
    "MSE_scores = list()\n",
    "R2_scikit = list()\n",
    "MSE_scikit = list()\n",
    "for n in range(1,6):\n",
    "    X = VandermondeMatrix(x, y, n)\n",
    "\n",
    "    beta_ols, z_predict_ols = linreg_ols(X, z)\n",
    "    \n",
    "\n",
    "    R2_scores.append(R2(z, z_predict_ols))\n",
    "    MSE_scores.append(MSE(z, z_predict_ols))\n",
    "    \n",
    "    # COMPARING WITH SCI-KIT LEARN\n",
    "\n",
    "    reg = LinearRegression().fit(X, z)\n",
    "    z_predict_scikit = X @ reg.coef_\n",
    "\n",
    "    R2_scikit.append(reg.score(X, z))\n",
    "    MSE_scikit.append(MSE(z, z_predict_scikit))\n",
    "    \n",
    "    print(\"n =\", n, \"\\n\")\n",
    "    #print(\"Own code | scikit-learn\")\n",
    "    #print(\"R2 ols\", R2(z, z_predict_ols), reg.score(X,z))\n",
    "    #print(\"MSE ols\", MSE(z, z_predict_ols), MSE(z, z_predict_scikit))\n",
    "                      \n",
    "                      \n",
    "    lambdas = [0.1, 0.01, 0.001, 0.0001]\n",
    "    \n",
    "    for la in lambdas:\n",
    "    #    beta_ridge, z_predict_ridge = ridgereg(X, z, lambda_ridge = la)\n",
    "        #print(\"Lambda:\", la)\n",
    "        #print(\"R2 ridge\", R2(z, z_predict_ridge))\n",
    "        #print(\"MSE ridge\", MSE(z, z_predict_ridge))\n",
    "        beta_lasso, z_predict_lasso, R2_lasso = lassoreg(X, z, lambda_lasso = la)\n",
    "        print(\"R2 lasso\", R2_lasso, \"lambda =\", la)\n",
    "        print(\"MSE lasso\", MSE(z, z_predict_lasso), \"lambda =\", la)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    #print(\"\\n\")\n",
    "    #print(\"******************************\")\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "n = range(1,6)\n",
    "#plt.scatter(n, R2_scores)\n",
    "#print(MSE_scores)\n",
    "#plt.scatter(n, MSE_scores, color='red')\n",
    "#plt.show()\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:cyan'\n",
    "ax1.set_xlabel('Model complexity')\n",
    "ax1.set_ylabel('R2', color=color)\n",
    "ax1.plot(n, R2_scores, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:orange'\n",
    "ax2.set_ylabel('MSE', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(n, MSE_scores, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "\n",
    "plt.grid()\n",
    "plt.show() \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(0, 1, 0.05)\n",
    "y = np.arange(0, 1, 0.05)\n",
    "\n",
    "x, y = np.meshgrid(x, y)\n",
    "\n",
    "z = FrankeFunction(x, y)\n",
    "\n",
    "x = np.ravel(x)\n",
    "y = np.ravel(y)\n",
    "z = np.ravel(z)\n",
    "\n",
    "z = z + 0.1 * np.random.randn(z.shape[0]) # noise level = 0.1\n",
    "\n",
    "X = VandermondeMatrix(x, y, 5)\n",
    "\n",
    "beta_ols, z_predict_ols = linreg_ols(X, z)\n",
    "beta_ridge, z_predict_ridge = ridgereg(X, z, lambda_ridge = 0.001)\n",
    "beta_lasso, z_predict_lasso, R2_lasso = lassoreg(X, z, lambda_lasso = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_upper_ols, c_lower_ols, diag_ols = confidence_interval(X, beta_ols, 1.96, 0.1)\n",
    "\n",
    "#for c in range(c_upper_ols.shape[0]):\n",
    "#    print('$ \\\\beta_{c} $', '&', round(c_lower_ols[c], 5), '&', round(c_upper_ols[c],5), '&', \"Var:\", round(diag_ols[c], 5), '\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c_upper_ridge, c_lower_ridge, diag_ridge = confidence_interval(X, beta_ridge, 1.96, 0.1)\n",
    "\n",
    "#for c in range(c_upper_ridge.shape[0]):\n",
    "#    print('$ \\\\beta_{c} $', '&', round(c_lower_ridge[c], 5), '&', round(c_upper_ridge[c],5), '&', \"Var:\", round(diag_ridge[c], 5), '\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_upper_lasso, c_lower_lasso, diag_lasso = confidence_interval(X, beta_lasso, 1.96, 0.1)\n",
    "\n",
    "#for c in range(c_upper_lasso.shape[0]):\n",
    "#    print('$ \\\\beta_{c} $', '&', round(c_lower_lasso[c], 5), '&', round(c_upper_lasso[c],5), '&', \"Var:\", round(diag_lasso[c], 5), '\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "x_axis = np.arange(0,21,1)\n",
    "\n",
    "plt.scatter(x_axis, c_upper_ols, label='Upper', color='cyan')\n",
    "plt.scatter(x_axis, c_lower_ols, label='Lower', color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.empty([50, 21])\n",
    "a[0] = beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bootstrap(X, z, statistic, method, number_of_bootstraps, la):\n",
    "    stat = np.empty([number_of_bootstraps, X.shape[1]])\n",
    "    max_idx = X.shape[0] # highest number of indices\n",
    "    beta = np.empty([number_of_bootstraps, X.shape[1]])\n",
    "    z_predict = np.empty([number_of_bootstraps, X.shape[0]])\n",
    "    R2_lasso = np.zeros(number_of_bootstraps)\n",
    "    \n",
    "    np.random.seed(4155)\n",
    "    \n",
    "    for i in range(number_of_bootstraps):\n",
    "           \n",
    "        if method == 'OLS':\n",
    "            idx = np.random.randint(0, max_idx, max_idx)\n",
    "            beta[i], z_predict[i] = linreg_ols(X[idx], z[idx])\n",
    "                            \n",
    "        elif method == 'Ridge':\n",
    "            idx = np.random.randint(0, max_idx, max_idx)\n",
    "            beta[i], z_predict[i] = ridgereg(X[idx], z[idx], la)\n",
    "            \n",
    "        elif method == 'LASSO':\n",
    "            idx = np.random.randint(0, max_idx, max_idx)\n",
    "            beta[i], z_predict[i], R2_lasso[i] = lassoreg(X[idx], z[idx], la)\n",
    "            \n",
    "        else:\n",
    "            break\n",
    "         \n",
    "        if statistic:\n",
    "            stat[i] = statistic(beta)\n",
    "        \n",
    "    if not statistic:\n",
    "        if method == 'OLS' or method == 'Ridge':\n",
    "            return beta, z_predict\n",
    "        if method == 'LASSO':\n",
    "            return beta, z_predict, R2_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = VandermondeMatrix(x, y, 5)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, z_train, z_test = train_test_split(X, z, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta_bootstrap_ols, z_predict_boot_ols = bootstrap(X_train, z_train, statistic = False, method = 'OLS', number_of_bootstraps = 5000, la = None)\n",
    "beta_bootstrap_ridge, z_predict_boot_ridge = bootstrap(X_train, z_train, statistic = False, method = 'Ridge', number_of_bootstraps = 5000, la = 0.01)\n",
    "beta_bootstrap_lasso, z_predict_boot_lasso, R2_lasso = bootstrap(X_train, z_train, statistic = False, method = 'LASSO', number_of_bootstraps = 5000, la = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta_mean_ols = np.mean(beta_bootstrap_ols, axis=0)\n",
    "beta_mean_ridge = np.mean(beta_bootstrap_ridge, axis=0)\n",
    "beta_mean_lasso = np.mean(beta_bootstrap_lasso, axis=0)\n",
    "\n",
    "z_pred_ols = X_test @ beta_mean_ols\n",
    "z_pred_ridge = X_test @ beta_mean_ridge\n",
    "z_pred_lasso = X_test @ beta_mean_lasso\n",
    "\n",
    "print('R2 \\n')\n",
    "print('OLS', R2(z_test, z_pred_ols), '\\n RIDGE', R2(z_test, z_pred_ridge), '\\n LASSO', R2(z_test, z_pred_lasso))\n",
    "print('\\n MSE \\n')\n",
    "print('OLS', MSE(z_test, z_pred_ols), '\\n RIDGE', MSE(z_test, z_pred_ridge), '\\n LASSO', MSE(z_test, z_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = VandermondeMatrix(x, y, 1)\n",
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "degrees = np.arange(1, 10, 1)\n",
    "R2_scores_ols = list()\n",
    "R2_scores_ridge = list()\n",
    "R2_scores_lasso = list()\n",
    "MSE_scores_ols = list()\n",
    "MSE_scores_ridge = list()\n",
    "MSE_scores_lasso = list()\n",
    "for n in degrees:\n",
    "    X = VandermondeMatrix(x, y, n)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X, z, test_size = 0.2)\n",
    "    \n",
    "    beta_bootstrap_ols, z_predict_boot_ols = bootstrap(X_train, z_train, statistic = False, method = 'OLS', number_of_bootstraps = 5000, la = None)\n",
    "    beta_bootstrap_ridge, z_predict_boot_ridge = bootstrap(X_train, z_train, statistic = False, method = 'Ridge', number_of_bootstraps = 5000, la = 0.01)\n",
    "    beta_bootstrap_lasso, z_predict_boot_lasso, R2_lasso = bootstrap(X_train, z_train, statistic = False, method = 'LASSO', number_of_bootstraps = 5000, la = 0.01)\n",
    "\n",
    "    \n",
    "    beta_mean_ols = np.mean(beta_bootstrap_ols, axis=0)\n",
    "    beta_mean_ridge = np.mean(beta_bootstrap_ridge, axis=0)\n",
    "    beta_mean_lasso = np.mean(beta_bootstrap_lasso, axis=0)\n",
    "\n",
    "    z_pred_ols = X_test @ beta_mean_ols\n",
    "    z_pred_ridge = X_test @ beta_mean_ridge\n",
    "    z_pred_lasso = X_test @ beta_mean_lasso\n",
    "\n",
    "    R2_scores_ols.append(R2(z_test, z_pred_ols))\n",
    "    R2_scores_ridge.append(R2(z_test, z_pred_ridge))\n",
    "    R2_scores_lasso.append(R2(z_test, z_pred_lasso))\n",
    "    MSE_scores_ols.append(MSE(z_test, z_pred_ols))\n",
    "    MSE_scores_ridge.append(MSE(z_test, z_pred_ridge))\n",
    "    MSE_scores_lasso.append(MSE(z_test, z_pred_lasso))\n",
    "    \n",
    "    \n",
    "    print('n:', n, '\\n')\n",
    "    print('R2 \\n')\n",
    "    print('OLS', R2(z_test, z_pred_ols), '\\n RIDGE', R2(z_test, z_pred_ridge), '\\n LASSO', R2(z_test, z_pred_lasso))\n",
    "    print('\\n MSE \\n')\n",
    "    print('OLS', MSE(z_test, z_pred_ols), '\\n RIDGE', MSE(z_test, z_pred_ridge), '\\n LASSO', MSE(z_test, z_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R2_scores_ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(R2_scores_ols)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:cyan'\n",
    "ax1.set_xlabel('Complexity')\n",
    "ax1.set_ylabel('R2', color=color)\n",
    "ax1.plot(degrees, R2_scores_ols, color=color, ls = '-', label= 'OLS')\n",
    "ax1.plot(degrees, R2_scores_ridge, color=color, ls=':', label = 'Ridge')\n",
    "ax1.plot(degrees, R2_scores_lasso, color=color, ls = '-.', label = 'Lasso')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "plt.legend()\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:orange'\n",
    "ax2.set_ylabel('MSE', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(degrees, MSE_scores_ols, color=color, ls = '-', label= 'OLS')\n",
    "ax2.plot(degrees, MSE_scores_ridge, color=color, ls = ':', label= 'Ridge')\n",
    "ax2.plot(degrees, MSE_scores_lasso, color=color, ls = '-.', label = 'Lasso')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "plt.legend()\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "\n",
    "plt.title('Model complexity (after 5000 bootstraps)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
