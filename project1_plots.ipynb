{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FrankeFunction(x,y):\n",
    "    term1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "    term2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "    term3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "    term4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "    return term1 + term2 + term3 + term4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VandermondeMatrix(x, y, n):\n",
    "    X = np.c_[np.ones(len(x))]\n",
    "    for i in range(1, n+1):\n",
    "        # x-terms\n",
    "        X = np.c_[X, x**(i)]\n",
    "        # y-terms\n",
    "        X = np.c_[X, y**(i)]\n",
    "        # Cross terms\n",
    "        for j in range(i-1, 0, -1):\n",
    "            X = np.c_[X, (x**(j))*(y**(i-j))]\n",
    "            \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linreg_ols(X, z):\n",
    "    \n",
    "    # Solving for beta\n",
    "    beta = np.linalg.inv(np.transpose(X).dot(X)).dot(np.transpose(X)).dot(z)\n",
    "    \n",
    "    y_predict_ols = X @ beta\n",
    "    \n",
    "    return beta, y_predict_ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridgereg(X, z, lambda_ridge):\n",
    "\n",
    "    # Solving for beta\n",
    "    beta_ridge = np.linalg.inv(np.transpose(X).dot(X) + lambda_ridge*np.identity(X.shape[1])).dot(np.transpose(X)).dot(z)\n",
    "\n",
    "    y_predict_ridge = X @ beta_ridge\n",
    "    \n",
    "    return beta_ridge, y_predict_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "def lassoreg(X, z, lambda_lasso):\n",
    "    \n",
    "    las = Lasso(alpha=lambda_lasso, fit_intercept = False)\n",
    "    las.fit(X, z)\n",
    "    \n",
    "    beta = las.coef_#[:,np.newaxis]\n",
    "    \n",
    "    y_predict_lasso = X @ beta\n",
    "    \n",
    "    R2_lasso = las.score(X, z)\n",
    "    \n",
    "    return beta, y_predict_lasso, R2_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def R2(y_data, y_model):\n",
    "    return 1 - np.sum((y_data - y_model) ** 2) / np.sum((y_data - np.mean(y_data)) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MSE(y_data,y_model):\n",
    "    n = np.size(y_model)\n",
    "    return np.sum((y_data-y_model)**2)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GENERATING DATA\n",
    "x = np.arange(0, 1, 0.05)\n",
    "y = np.arange(0, 1, 0.05)\n",
    "\n",
    "#x = np.arange(0, 1, 0.009)\n",
    "#y = np.arange(0, 1, 0.009)\n",
    "\n",
    "\n",
    "x, y = np.meshgrid(x, y)\n",
    "\n",
    "z = FrankeFunction(x, y)\n",
    "\n",
    "x = np.ravel(x)\n",
    "y = np.ravel(y)\n",
    "z = np.ravel(z)\n",
    "\n",
    "#z = z + 0.1 * np.random.randn(z.shape[0]) # noise level = 0.1\n",
    "X = VandermondeMatrix(x, y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta_lasso, z_predict_lasso, R2_lasso = lassoreg(X, z, 0.001)\n",
    "    \n",
    "print(MSE(z, z_predict_lasso))\n",
    "print(R2_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "x = np.arange(0, 1, 0.05)\n",
    "y = np.arange(0, 1, 0.05)\n",
    "\n",
    "x, y = np.meshgrid(x, y)\n",
    "\n",
    "z = FrankeFunction(x, y)\n",
    "\n",
    "x = np.ravel(x)\n",
    "y = np.ravel(y)\n",
    "z = np.ravel(z)\n",
    "\n",
    "X = VandermondeMatrix(x, y, 5)\n",
    "\n",
    "#noise = [0, 0.1, 0.2, 0.3, 0.4]\n",
    "noise = np.arange(0,0.4,0.01)\n",
    "#noise = np.arange(0, 1, 0.001)\n",
    "\n",
    "R2_scores = list()\n",
    "MSE_scores = list()\n",
    "R2_scores_ridge = list()\n",
    "MSE_scores_ridge = list()\n",
    "R2_scores_lasso = list()\n",
    "MSE_scores_lasso = list()\n",
    "    \n",
    "for N in noise:\n",
    "    z = z + N * np.random.randn(z.shape[0])\n",
    "\n",
    "    beta_ols, z_predict_ols = linreg_ols(X, z)\n",
    "    \n",
    "    R2_scores.append(R2(z, z_predict_ols))\n",
    "    MSE_scores.append(MSE(z, z_predict_ols))\n",
    "\n",
    "    beta_ridge, z_predict_ridge = ridgereg(X, z, 0.001)\n",
    "    \n",
    "    R2_scores_ridge.append(R2(z, z_predict_ridge))\n",
    "    MSE_scores_ridge.append(MSE(z, z_predict_ridge))\n",
    "    \n",
    "    beta_lasso, z_predict_lasso, R2_lasso = lassoreg(X, z, 0.001)\n",
    "    \n",
    "    R2_scores_lasso.append(R2_lasso)\n",
    "    MSE_scores_lasso.append(MSE(z, z_predict_lasso))\n",
    "    \n",
    "    # Regenerate z\n",
    "    z = 0\n",
    "    x = np.arange(0, 1, 0.05)\n",
    "    y = np.arange(0, 1, 0.05)\n",
    "\n",
    "    x, y = np.meshgrid(x, y)\n",
    "\n",
    "    z = FrankeFunction(x, y)\n",
    "    z = np.ravel(z)\n",
    "    \n",
    "    \n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:cyan'\n",
    "ax1.set_xlabel('Noise')\n",
    "ax1.set_ylabel('R2', color=color)\n",
    "ax1.plot(noise, R2_scores, color=color, ls = '-', label = 'OLS')\n",
    "ax1.plot(noise, R2_scores_ridge, color=color, ls = ':', label = 'Ridge')\n",
    "ax1.plot(noise, R2_scores_lasso, color=color, ls = '-.', label = 'Lasso')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:orange'\n",
    "ax2.set_ylabel('MSE', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(noise, MSE_scores, color=color, ls = '-', label = 'OLS')\n",
    "ax2.plot(noise, MSE_scores_ridge, color=color, ls = ':', label = 'Ridge')\n",
    "ax2.plot(noise, MSE_scores_lasso, color=color, ls = '-.', label = 'Lasso')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "\n",
    "#ax1.legend(loc='best')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('MSE and R2 as a function of noise, $n$ = 5')\n",
    "plt.grid(axis='both')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(MSE_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = VandermondeMatrix(x, y, 5)\n",
    "\n",
    "#lambdas = [0.1, 0.01, 0.001, 0.0001]\n",
    "lambdas = np.arange(0,0.1,0.0001)\n",
    "\n",
    "MSE_scores_ridge = list()\n",
    "MSE_scores_lasso = list()\n",
    "R2_scores_ridge = list()\n",
    "R2_scores_lasso = list()\n",
    "for la in lambdas:\n",
    "    beta_ridge, z_predict_ridge = ridgereg(X, z, lambda_ridge = la)\n",
    "    beta_lasso, z_predict_lasso, R2_lasso = lassoreg(X, z, lambda_lasso = la)\n",
    "    MSE_scores_ridge.append(MSE(z, z_predict_ridge))\n",
    "    MSE_scores_lasso.append(MSE(z, z_predict_lasso))\n",
    "    R2_scores_ridge.append(R2(z, z_predict_ridge))\n",
    "    R2_scores_lasso.append(R2_lasso)\n",
    "        \n",
    "#plt.plot(lambdas, MSE_scores_ridge, label='Ridge')\n",
    "#plt.xlabel('Lambda')\n",
    "#plt.ylabel('MSE Score')\n",
    "#plt.plot(lambdas, MSE_scores_lasso, label='Lasso')\n",
    "#plt.show()\n",
    "\"\"\"\n",
    "# PLOT OF LAMBDAS FOR RIDGE REGRESSION\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:cyan'\n",
    "ax1.set_xlabel('Lambdas')\n",
    "ax1.set_ylabel('R2', color=color)\n",
    "ax1.plot(lambdas, R2_scores_ridge, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:orange'\n",
    "ax2.set_ylabel('MSE', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(lambdas, MSE_scores_ridge, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "\n",
    "plt.title('Ridge regression (5-th order polynomial)')\n",
    "plt.grid()\n",
    "plt.show() \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# PLOT OF LAMBDAS FOR LASSO REGRESSION\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:cyan'\n",
    "ax1.set_xlabel('Lambdas')\n",
    "ax1.set_ylabel('R2', color=color)\n",
    "ax1.plot(lambdas, R2_scores_ridge, color=color, ls=':', label = 'Ridge')\n",
    "ax1.plot(lambdas, R2_scores_lasso, color=color, ls = '-.', label = 'Lasso')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "plt.legend()\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:orange'\n",
    "ax2.set_ylabel('MSE', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(lambdas, MSE_scores_ridge, color=color, ls = ':', label= 'Ridge')\n",
    "ax2.plot(lambdas, MSE_scores_lasso, color=color, ls = '-.', label = 'Lasso')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "plt.legend()\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "\n",
    "plt.title('Variation of lambdas (5-th order polynomial)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R2_scores = list()\n",
    "MSE_scores = list()\n",
    "R2_scores_ridge = list()\n",
    "MSE_scores_ridge = list()\n",
    "R2_scores_lasso = list()\n",
    "MSE_scores_lasso = list()\n",
    "\n",
    "for n in range(1,6):\n",
    "    X = VandermondeMatrix(x, y, n)\n",
    "\n",
    "    beta_ols, z_predict_ols = linreg_ols(X, z)    \n",
    "    beta_ridge, z_predict_ridge = ridgereg(X, z, 0.001)\n",
    "    beta_lasso, z_predict_lasso, R2_lasso = lassoreg(X, z, 0.001)\n",
    "    \n",
    "    R2_scores.append(R2(z, z_predict_ols))\n",
    "    MSE_scores.append(MSE(z, z_predict_ols))\n",
    "    R2_scores_ridge.append(R2(z, z_predict_ridge))\n",
    "    MSE_scores_ridge.append(MSE(z, z_predict_ridge))\n",
    "    R2_scores_lasso.append(R2_lasso)\n",
    "    MSE_scores_lasso.append(MSE(z, z_predict_lasso))\n",
    "\n",
    "#    lambdas = [0.1, 0.01, 0.001, 0.0001]\n",
    "    \n",
    "#    for la in lambdas:\n",
    "#        beta_ridge, z_predict_ridge = ridgereg(X, z, lambda_ridge = la)\n",
    "#        beta_lasso, z_predict_lasso, R2_lasso = lassoreg(X, z, lambda_lasso = la)\n",
    "\n",
    "n = range(1,6)\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:cyan'\n",
    "ax1.set_xlabel('Model complexity (no noise)')\n",
    "ax1.set_ylabel('R2', color=color)\n",
    "ax1.plot(n, R2_scores, color=color, ls = '-', label = 'OLS')\n",
    "ax1.plot(n, R2_scores_ridge, color=color, ls = ':', label = 'Ridge')\n",
    "ax1.plot(n, R2_scores_lasso, color=color, ls = '-.', label = 'Lasso')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "plt.legend()\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:orange'\n",
    "ax2.set_ylabel('MSE', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(n, MSE_scores, color=color, ls = '-', label = 'OLS')\n",
    "ax2.plot(n, MSE_scores_ridge, color=color, ls = ':', label = 'Ridge')\n",
    "ax2.plot(n, MSE_scores_lasso, color=color, ls = '-.', label = 'Lasso')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "plt.legend()\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "\n",
    "plt.title('Ordinary Least Squares')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "R2_scores = list()\n",
    "MSE_scores_train = list()\n",
    "MSE_scores_test = list()\n",
    "for n in range(1,10):\n",
    "    X = VandermondeMatrix(x, y, n)\n",
    "    \n",
    "    #np.random.shuffle(X)\n",
    "    \n",
    "    X_train, X_test, z_train, z_test = train_test_split(X, z, test_size = 0.2)\n",
    "    \n",
    "    beta_ols_train, z_predict_ols_train = linreg_ols(X_train, z_train)\n",
    "    z_predict_ols_test = X_test @ beta_ols_train\n",
    "    \n",
    "    MSE_scores_train.append(MSE(z_train, z_predict_ols_train))\n",
    "    MSE_scores_test.append(MSE(z_test, z_predict_ols_test))\n",
    "    \n",
    "n = range(1,10)\n",
    "\n",
    "plt.plot(n, MSE_scores_train, label='Train')\n",
    "plt.plot(n, MSE_scores_test, label='Test')\n",
    "plt.xlabel('Model complexity')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "\n",
    "\n",
    "fig = pyplot.figure()\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "ax.scatter(x, y, z_predict_ols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The Franke function (code provided in the assignment text)\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import numpy as np\n",
    "from random import random, seed\n",
    "\n",
    "def FrankeFunction(x,y):\n",
    "    term1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "    term2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "    term3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "    term4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "    return term1 + term2 + term3 + term4\n",
    "\n",
    "x = np.arange(0, 1, 0.05)\n",
    "y = np.arange(0, 1, 0.05)\n",
    "\n",
    "x, y = np.meshgrid(x, y)\n",
    "\n",
    "z = FrankeFunction(x, y)\n",
    "\n",
    "x = np.ravel(x)\n",
    "y = np.ravel(y)\n",
    "z = np.ravel(z)\n",
    "\n",
    "#z = z + 0.1 * np.random.randn(z.shape[0]) # noise level = 0.1\n",
    "X = VandermondeMatrix(x, y, 5)\n",
    "\n",
    "beta_ols, z_predict_ols = linreg_ols(X, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "\n",
    "\n",
    "x = np.arange(0, 1, 0.05)\n",
    "y = np.arange(0, 1, 0.05)\n",
    "\n",
    "x, y = np.meshgrid(x, y)\n",
    "\n",
    "z = FrankeFunction(x, y)\n",
    "\n",
    "\n",
    "# Plot the surface\n",
    "#surf = ax.plot_surface(x, y, z, cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "\n",
    "ax.scatter(x, y, z_predict_ols)\n",
    "\n",
    "# Customize the z axis\n",
    "#ax.set_zlim(-0.10, 1.40)\n",
    "#ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "#ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "# Add a color bar which maps values to colors\n",
    "#fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GENERATING DATA\n",
    "x = np.arange(0, 1, 0.05)\n",
    "y = np.arange(0, 1, 0.05)\n",
    "\n",
    "#x = np.arange(0, 1, 0.009)\n",
    "#y = np.arange(0, 1, 0.009)\n",
    "\n",
    "\n",
    "x, y = np.meshgrid(x, y)\n",
    "\n",
    "z = FrankeFunction(x, y)\n",
    "\n",
    "x = np.ravel(x)\n",
    "y = np.ravel(y)\n",
    "z = np.ravel(z)\n",
    "\n",
    "\n",
    "z = z + 0.1 * np.random.randn(z.shape[0]) # noise level = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE_scores_ridge = list()\n",
    "MSE_scores_lasso = list()\n",
    "R2_scores_ridge = list()\n",
    "R2_scores_lasso = list()\n",
    "for n in range(1,6):\n",
    "\n",
    "    X = VandermondeMatrix(x, y, n)\n",
    "\n",
    "    lambdas = np.arange(0,0.1,0.0001)\n",
    "\n",
    "    for la in lambdas:\n",
    "        beta_ridge, z_predict_ridge = ridgereg(X, z, lambda_ridge = la)\n",
    "        beta_lasso, z_predict_lasso, R2_lasso = lassoreg(X, z, lambda_lasso = la)\n",
    "        MSE_scores_ridge.append(MSE(z, z_predict_ridge))\n",
    "        MSE_scores_lasso.append(MSE(z, z_predict_lasso))\n",
    "        R2_scores_ridge.append(R2(z, z_predict_ridge))\n",
    "        R2_scores_lasso.append(R2_lasso)\n",
    "    \n",
    "    print(n)\n",
    "    print(len(R2_scores_ridge))\n",
    "    \n",
    "\"\"\" \n",
    "# PLOT OF LAMBDAS FOR RIDGE REGRESSION\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = 'tab:cyan'\n",
    "    ax1.set_xlabel('Lambdas')\n",
    "    ax1.set_ylabel('R2', color=color)\n",
    "    ax1.plot(lambdas, R2_scores_ridge, color=color)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color = 'tab:orange'\n",
    "    ax2.set_ylabel('MSE', color=color)  # we already handled the x-label with ax1\n",
    "    ax2.plot(lambdas, MSE_scores_ridge, color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "\n",
    "    plt.title('Ridge regression (3rd order polynomial)')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PLOT OF LAMBDAS FOR RIDGE REGRESSION\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:cyan'\n",
    "ax1.set_xlabel('Lambdas')\n",
    "ax1.set_ylabel('R2', color=color)\n",
    "ax1.plot(lambdas, R2_scores_ridge[0:1000], color=color, label = 'n = 1')\n",
    "ax1.plot(lambdas, R2_scores_ridge[1000:2000], color=color, linestyle = ':', label = 'n = 2')\n",
    "ax1.plot(lambdas, R2_scores_ridge[2000:3000], color=color, linestyle = '-.', label = 'n = 3')\n",
    "ax1.plot(lambdas, R2_scores_ridge[3000:4000], color=color, linestyle = '--', label = 'n = 4')\n",
    "ax1.plot(lambdas, R2_scores_ridge[4000:5000], label = 'n = 5')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "plt.legend()\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:orange'\n",
    "ax2.set_ylabel('MSE', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(lambdas, MSE_scores_ridge[0:1000], color=color, label = 'MSE n = 1')\n",
    "ax2.plot(lambdas, MSE_scores_ridge[1000:2000], color=color, linestyle = ':', label = 'MSE n = 2')\n",
    "ax2.plot(lambdas, MSE_scores_ridge[2000:3000], color=color, linestyle = '-.', label = 'MSE n = 3')\n",
    "ax2.plot(lambdas, MSE_scores_ridge[3000:4000], color=color, linestyle = '--', label = 'MSE n = 4')\n",
    "ax2.plot(lambdas, MSE_scores_ridge[4000:5000], label = 'MSE n = 5')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "\n",
    "plt.title('Ridge regression (3rd order polynomial)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
